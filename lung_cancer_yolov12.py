# -*- coding: utf-8 -*-
"""Lung Cancer YOLOv12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-PkXoJL287u-swVSs0fIo1DCYJDdrxYt
"""

# Install required packages
!pip install torch torchvision ultralytics
!pip install kaggle kagglehub
!pip install scikit-learn matplotlib seaborn pandas opencv-python pydicom albumentations

# Import necessary libraries
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
import cv2
import pandas as pd
import kagglehub
import json
import shutil
from tqdm import tqdm
import glob
import pydicom

# Download the Crowds Cure Cancer 2017 dataset
dataset_path = kagglehub.dataset_download("kmader/crowds-cure-cancer-2017")
print("Path to dataset files:", dataset_path)

# Create directories for YOLO format
base_dir = '/content/lung_cancer_yolo'
images_dir = f'{base_dir}/images'
labels_dir = f'{base_dir}/labels'
train_dir = f'{base_dir}/train'
val_dir = f'{base_dir}/val'
test_dir = f'{base_dir}/test'

for dir_path in [base_dir, images_dir, labels_dir, train_dir, val_dir, test_dir]:
    os.makedirs(dir_path, exist_ok=True)

# Define lung window function for CT scans
def apply_lung_window(dicom_image, center=-600, width=1500):
    """Apply lung window to highlight lung tissue."""
    image = dicom_image.copy()
    min_value = center - width//2
    max_value = center + width//2
    image[image < min_value] = min_value
    image[image > max_value] = max_value
    return (image - min_value) / (max_value - min_value) * 255

# Process the dataset for YOLO format
def process_dataset():
    # Find annotation files
    annotation_files = glob.glob(f"{dataset_path}/**/annotations/*.json", recursive=True)
    print(f"Found {len(annotation_files)} annotation files")

    if len(annotation_files) == 0:
        print("Checking the directory structure...")
        all_files = glob.glob(f"{dataset_path}/**/*", recursive=True)
        for i, file in enumerate(all_files[:20]):  # Print first 20 files to understand structure
            print(f"File {i}: {file}")

    # Create a mapping of classes
    class_mapping = {
        'Lung cancer': 0,
        'Lung nodule': 1,
        'Metastasis': 2,
        'Cancer': 0,  # Alternative label that might be in the dataset
        'Nodule': 1,  # Alternative label
        'nodule': 1   # Case variation
    }

    processed_count = 0

    # Process each annotation file
    for ann_file in tqdm(annotation_files):
        try:
            with open(ann_file, 'r') as f:
                annotation = json.load(f)

                # Extract image path from annotation
                # Adjust this path extraction based on your examination of the dataset structure
                rel_path = annotation.get('filename', '')
                if not rel_path:
                    print(f"No filename in annotation: {ann_file}")
                    continue

                # Try different possible locations for the image
                possible_image_paths = [
                    os.path.join(os.path.dirname(os.path.dirname(ann_file)), 'images', rel_path),
                    os.path.join(os.path.dirname(os.path.dirname(ann_file)), rel_path),
                    os.path.join(dataset_path, 'images', rel_path),
                    os.path.join(dataset_path, rel_path)
                ]

                image_path = None
                for path in possible_image_paths:
                    if os.path.exists(path):
                        image_path = path
                        break

                if not image_path:
                    print(f"Image not found for annotation: {ann_file}, filename: {rel_path}")
                    continue

                # For DICOM files, convert to PNG
                if image_path.lower().endswith('.dcm'):
                    try:
                        dicom = pydicom.dcmread(image_path)
                        img_array = dicom.pixel_array

                        # Apply lung windowing
                        img_array = apply_lung_window(img_array)

                        # Create filename for PNG
                        png_filename = os.path.splitext(os.path.basename(image_path))[0] + '.png'
                        png_path = os.path.join(images_dir, png_filename)

                        # Save as PNG
                        cv2.imwrite(png_path, img_array.astype('uint8'))
                        image_filename = png_filename
                        img_width, img_height = img_array.shape[1], img_array.shape[0]
                    except Exception as e:
                        print(f"Error processing DICOM file {image_path}: {e}")
                        continue
                else:
                    # For other formats, just copy
                    try:
                        image_filename = os.path.basename(image_path)
                        shutil.copy(image_path, os.path.join(images_dir, image_filename))
                        img = cv2.imread(image_path)
                        if img is None:
                            print(f"Unable to read image: {image_path}")
                            continue
                        img_height, img_width = img.shape[:2]
                    except Exception as e:
                        print(f"Error copying image {image_path}: {e}")
                        continue

                # Create YOLO format label file
                label_filename = os.path.splitext(image_filename)[0] + '.txt'
                label_path = os.path.join(labels_dir, label_filename)

                with open(label_path, 'w') as label_file:
                    # Process annotations - look for objects in different places in the JSON
                    objects_to_process = []

                    # Try different possible locations for annotations
                    if 'objects' in annotation:
                        objects_to_process = annotation['objects']
                    elif 'annotations' in annotation:
                        objects_to_process = annotation['annotations']

                    if not objects_to_process:
                        print(f"No objects found in annotation: {ann_file}")
                        continue

                    for obj in objects_to_process:
                        # Try different possible name fields
                        class_name = None
                        for key in ['name', 'class', 'label', 'category']:
                            if key in obj:
                                class_name = obj[key]
                                break

                        if not class_name:
                            continue

                        if class_name in class_mapping:
                            class_id = class_mapping[class_name]

                            # Extract bounding box - try different possible formats
                            x1, y1, width, height = None, None, None, None

                            # Format 1: x, y, width, height
                            if all(k in obj for k in ['x', 'y', 'width', 'height']):
                                x1 = obj['x']
                                y1 = obj['y']
                                width = obj['width']
                                height = obj['height']
                            # Format 2: xmin, ymin, xmax, ymax
                            elif all(k in obj for k in ['xmin', 'ymin', 'xmax', 'ymax']):
                                x1 = obj['xmin']
                                y1 = obj['ymin']
                                width = obj['xmax'] - obj['xmin']
                                height = obj['ymax'] - obj['ymin']
                            # Format 3: bbox as [x, y, width, height]
                            elif 'bbox' in obj and len(obj['bbox']) == 4:
                                x1, y1, width, height = obj['bbox']

                            if x1 is None:
                                continue

                            # Convert to YOLO format (normalized center x, center y, width, height)
                            x_center = (x1 + width/2) / img_width
                            y_center = (y1 + height/2) / img_height
                            norm_width = width / img_width
                            norm_height = height / img_height

                            # Ensure values are within [0, 1]
                            x_center = max(0, min(1, x_center))
                            y_center = max(0, min(1, y_center))
                            norm_width = max(0, min(1, norm_width))
                            norm_height = max(0, min(1, norm_height))

                            # Write to label file
                            label_file.write(f"{class_id} {x_center} {y_center} {norm_width} {norm_height}\n")

                processed_count += 1
        except Exception as e:
            print(f"Error processing {ann_file}: {e}")

    print(f"Successfully processed {processed_count} files")
    return processed_count

# Call the function to process dataset
processed_count = process_dataset()

if processed_count == 0:
    # If no files were processed, let's create a small synthetic dataset for demonstration
    print("Creating synthetic dataset for demonstration...")

    # Create 20 synthetic examples
    for i in range(20):
        # Create a blank image with a simulated nodule
        img = np.zeros((512, 512), dtype=np.uint8)
        # Add background texture
        img += np.random.randint(20, 40, size=(512, 512), dtype=np.uint8)

        # Create a simulated nodule
        center_x = np.random.randint(100, 412)
        center_y = np.random.randint(100, 412)
        radius = np.random.randint(10, 30)

        # Draw the nodule (brighter circle)
        cv2.circle(img, (center_x, center_y), radius, 150, -1)
        # Add some gaussian blur for realism
        img = cv2.GaussianBlur(img, (5, 5), 0)

        # Save the image
        img_filename = f"synthetic_lung_{i}.png"
        cv2.imwrite(os.path.join(images_dir, img_filename), img)

        # Create label
        x_center = center_x / 512
        y_center = center_y / 512
        width = (radius * 2) / 512
        height = (radius * 2) / 512

        # Determine class randomly (0: cancer, 1: nodule)
        class_id = np.random.choice([0, 1], p=[0.3, 0.7])

        with open(os.path.join(labels_dir, f"synthetic_lung_{i}.txt"), 'w') as f:
            f.write(f"{class_id} {x_center} {y_center} {width} {height}\n")

    processed_count = 20
    print(f"Created {processed_count} synthetic examples")

# Split data into training, validation, and test sets (70%, 20%, 10%)
def split_data():
    all_images = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]

    if not all_images:
        print("No images found in images directory!")
        return False

    print(f"Splitting {len(all_images)} images into train/val/test sets")
    np.random.shuffle(all_images)

    n_total = len(all_images)
    n_train = int(0.7 * n_total)
    n_val = int(0.2 * n_total)

    train_images = all_images[:n_train]
    val_images = all_images[n_train:n_train+n_val]
    test_images = all_images[n_train+n_val:]

    # Copy images and labels to respective directories
    for img_set, target_dir in [(train_images, train_dir),
                               (val_images, val_dir),
                               (test_images, test_dir)]:

        os.makedirs(target_dir, exist_ok=True)
        for img_name in img_set:
            img_path = os.path.join(images_dir, img_name)
            if os.path.exists(img_path):
                shutil.copy(img_path, os.path.join(target_dir, img_name))

                # Copy corresponding label file
                label_name = os.path.splitext(img_name)[0] + '.txt'
                label_path = os.path.join(labels_dir, label_name)
                if os.path.exists(label_path):
                    shutil.copy(label_path, os.path.join(target_dir, label_name))

    print(f"Split dataset: {len(train_images)} training, {len(val_images)} validation, {len(test_images)} test images")
    return True

# Split the dataset
split_success = split_data()

if not split_success:
    print("Error splitting dataset. Check that there are images in the images directory.")

# Create YAML configuration for YOLO training
class_names = {
    0: 'Lung cancer',
    1: 'Lung nodule',
    2: 'Metastasis'
}

yaml_content = f"""
path: {base_dir}
train: {train_dir}
val: {val_dir}
test: {test_dir}

nc: {len(class_names)}  # number of classes
names: {class_names}  # class names
"""

yaml_path = f'{base_dir}/lung_cancer_data.yaml'
with open(yaml_path, 'w') as f:
    f.write(yaml_content)

print(f"Created YAML configuration at {yaml_path}")

# Install YOLOv12
!pip install git+https://github.com/ultralytics/ultralytics.git

# Check if YOLOv12 is available
try:
    # Try to list available YOLO versions
    print("Checking available YOLO versions...")

    from ultralytics import YOLO
    import ultralytics
    print(f"Ultralytics version: {ultralytics.__version__}")

    # Try to load YOLOv12 specifically
    try:
        model = YOLO('yolov12n.pt')  # Attempting to load YOLOv12 nano
        print("Successfully loaded YOLOv12 model")
    except:
        print("YOLOv12 model not found, checking available models...")
        # Fall back to latest available
        available_models = ['yolov12n.pt', 'yolov12s.pt', 'yolov12m.pt', 'yolov12l.pt', 'yolov12x.pt',
                            'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']

        for model_name in available_models:
            try:
                model = YOLO(model_name)
                print(f"Successfully loaded {model_name}")
                break
            except:
                continue
        else:
            print("Failed to load any YOLO model")

except Exception as e:
    print(f"Error checking YOLO versions: {e}")

# Configure and start training
try:
    # Initialize model with YOLOv12
    model = YOLO('yolov12n.pt')  # Use the nano version first

    # YOLOv12 specific training configuration
    results = model.train(
        data=yaml_path,
        epochs=50,
        patience=10,
        batch=8,
        imgsz=640,
        pretrained=True,
        optimizer='SGD',
        lr0=1e-3,
        lrf=1e-4,
        weight_decay=5e-4,
        momentum=0.937,
        warmup_epochs=3,
        save=True,
        save_period=5,
        project=base_dir,
        name='lung_cancer_model_v12',
        exist_ok=True,
        # YOLOv12 specific parameters
        mosaic=0.5,  # Mosaic augmentation
        mixup=0.5,   # Mixup augmentation
        cutmix=0.0,  # Cutmix augmentation
        copy_paste=0.0,  # Copy-paste augmentation
        dropout=0.0,  # Dropout rate
        agnostic_nms=True,  # Class-agnostic NMS
        verbose=True,  # Print verbose output
        resume=False  # Resume training from last checkpoint
    )
    print("Training completed successfully")
except Exception as e:
    print(f"Error during training: {e}")
    print("Falling back to best available YOLO model...")
    try:
        # Try with YOLOv8 or best available version
        model = YOLO('yolov8n.pt')
        results = model.train(
            data=yaml_path,
            epochs=50,
            patience=10,
            batch=8,
            imgsz=640,
            pretrained=True,
        )
        print("Training completed with fallback model")
    except Exception as e2:
        print(f"Error during fallback training: {e2}")

# Evaluate the model
try:
    val_results = model.val()
    print(f"mAP50-95: {val_results.box.map}")
    print(f"Precision: {val_results.box.precision}")
    print(f"Recall: {val_results.box.recall}")
except Exception as e:
    print(f"Error during validation: {e}")

# Test inference on a sample image
test_images = glob.glob(f"{test_dir}/*.png")
if test_images:
    test_img = test_images[0]
    print(f"Running inference on {test_img}")

    try:
        results = model.predict(test_img, conf=0.25)

        # Display results
        img = cv2.imread(test_img)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        plt.figure(figsize=(10, 10))
        plt.imshow(img)

        for result in results:
            boxes = result.boxes.xyxy.cpu().numpy()
            confs = result.boxes.conf.cpu().numpy()
            cls = result.boxes.cls.cpu().numpy().astype(int)

            for box, conf, cl in zip(boxes, confs, cls):
                x1, y1, x2, y2 = box.astype(int)
                class_name = class_names.get(cl, f"Class {cl}")
                plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                                fill=False, edgecolor='red', linewidth=2))
                plt.text(x1, y1-10, f"{class_name} {conf:.2f}",
                        color='white', fontsize=12, backgroundcolor='red')

        plt.title("YOLOv12 Model Prediction")
        plt.axis('off')
        plt.savefig(f'{base_dir}/sample_prediction_v12.png')
        plt.show()

        print("Inference completed successfully")
    except Exception as e:
        print(f"Error during inference: {e}")
else:
    print("No test images found")

# Export model for deployment
try:
    model.export(format='onnx', dynamic=True)
    print(f"YOLOv12 model exported successfully")
except Exception as e:
    print(f"Error exporting model: {e}")

# Visualize training results
try:
    # Plot metrics from training
    metrics = ['train/box_loss', 'train/cls_loss', 'train/dfl_loss',   # Training losses
               'metrics/precision', 'metrics/recall',                  # Performance metrics
               'val/box_loss', 'val/cls_loss', 'val/dfl_loss']         # Validation losses

    plt.figure(figsize=(15, 10))

    for i, metric in enumerate(metrics):
        if metric in results.results_dict:
            plt.subplot(3, 3, i+1)
            plt.plot(results.results_dict[metric])
            plt.title(metric)
            plt.xlabel('Epoch')
            plt.grid(True)

    plt.tight_layout()
    plt.savefig(f'{base_dir}/training_metrics_v12.png')
    plt.show()

    print("Training metrics visualization completed")
except Exception as e:
    print(f"Error visualizing metrics: {e}")

