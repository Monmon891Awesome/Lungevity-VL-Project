{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK1X0kztWPKC"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install ultralytics\n",
        "!pip install pydicom\n",
        "!pip install scikit-image\n",
        "!pip install matplotlib pandas seaborn opencv-python --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import pydicom\n",
        "from skimage import exposure\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "from IPython.display import display, Image as DisplayImage\n",
        "from google.colab import drive\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import time"
      ],
      "metadata": {
        "id": "2oqd1cXvYLRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import pydicom\n",
        "from skimage import exposure\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "from IPython.display import display, Image as DisplayImage\n",
        "from google.colab import drive\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# CELL 3 - MOUNT GOOGLE DRIVE & SET UP DIRECTORIES\n",
        "def setup_environment():\n",
        "    \"\"\"\n",
        "    Mount Google Drive and set up project directories\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing paths to main directories\n",
        "    \"\"\"\n",
        "    # Mount Google Drive\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Set paths\n",
        "    base_dir = '/content/drive/MyDrive/LungCancerProject'\n",
        "    data_dir = f'{base_dir}/data'\n",
        "    models_dir = f'{base_dir}/models'\n",
        "    output_dir = f'{base_dir}/output'\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    for directory in [base_dir, data_dir, models_dir, output_dir]:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    print(\"Directory structure created in Google Drive\")\n",
        "\n",
        "    return {\n",
        "        'base_dir': base_dir,\n",
        "        'data_dir': data_dir,\n",
        "        'models_dir': models_dir,\n",
        "        'output_dir': output_dir\n",
        "    }\n",
        "\n",
        "# Call the function to set up directories\n",
        "paths = setup_environment()"
      ],
      "metadata": {
        "id": "GlgLXop4YLPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dicom(dicom_path, output_path, window_center=-600, window_width=1500):\n",
        "    \"\"\"\n",
        "    Read a DICOM file, apply windowing, and save as JPG\n",
        "\n",
        "    Args:\n",
        "        dicom_path: Path to the DICOM file\n",
        "        output_path: Path to save the processed image\n",
        "        window_center: Window center for visualization (default: -600 for lungs)\n",
        "        window_width: Window width for visualization (default: 1500 for lungs)\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the saved image\n",
        "    \"\"\"\n",
        "    # Read DICOM file\n",
        "    dicom = pydicom.dcmread(dicom_path)\n",
        "\n",
        "    # Get pixel array\n",
        "    img = dicom.pixel_array\n",
        "\n",
        "    # Apply windowing\n",
        "    img = exposure.rescale_intensity(\n",
        "        img,\n",
        "        in_range=(window_center - window_width/2, window_center + window_width/2),\n",
        "        out_range=(0, 255)\n",
        "    )\n",
        "\n",
        "    # Convert to uint8\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    # Save as JPG\n",
        "    cv2.imwrite(output_path, img)\n",
        "    return output_path"
      ],
      "metadata": {
        "id": "2UTPaS_BYLMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dicom_folder(input_folder, output_folder, label=None):\n",
        "    \"\"\"\n",
        "    Process all DICOM files in a folder and convert them to images\n",
        "\n",
        "    Args:\n",
        "        input_folder: Folder containing DICOM files\n",
        "        output_folder: Folder to save processed images\n",
        "        label: Class label for the images (optional)\n",
        "\n",
        "    Returns:\n",
        "        list: List of paths to processed images\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    processed_images = []\n",
        "\n",
        "    for file in tqdm(glob.glob(os.path.join(input_folder, \"*.dcm\")), desc=f\"Processing {input_folder}\"):\n",
        "        filename = os.path.basename(file).replace('.dcm', '.jpg')\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        preprocess_dicom(file, output_path)\n",
        "\n",
        "        if label:\n",
        "            processed_images.append((output_path, label))\n",
        "        else:\n",
        "            processed_images.append(output_path)\n",
        "\n",
        "    return processed_images\n"
      ],
      "metadata": {
        "id": "wAqLtwECYLKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yolo_annotations(image_path, label_id, boxes):\n",
        "    \"\"\"\n",
        "    Create YOLO format annotations for an image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image\n",
        "        label_id: Class ID (0-based)\n",
        "        boxes: List of bounding boxes in format [x, y, width, height] (normalized)\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the annotation file\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    # Create annotation file path\n",
        "    txt_path = image_path.replace('.jpg', '.txt').replace('/images/', '/labels/')\n",
        "    os.makedirs(os.path.dirname(txt_path), exist_ok=True)\n",
        "\n",
        "    with open(txt_path, 'w') as f:\n",
        "        for box in boxes:\n",
        "            # Normalize box coordinates to [0-1]\n",
        "            x_center = (box[0] + box[2]/2) / width\n",
        "            y_center = (box[1] + box[3]/2) / height\n",
        "            w = box[2] / width\n",
        "            h = box[3] / height\n",
        "\n",
        "            # Write in YOLO format: class x_center y_center width height\n",
        "            f.write(f\"{label_id} {x_center} {y_center} {w} {h}\\n\")\n",
        "\n",
        "    return txt_path\n"
      ],
      "metadata": {
        "id": "poPxkcLAYLIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data_root, output_folder, labels, annotations=None, split_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Prepare dataset in YOLO format\n",
        "\n",
        "    Args:\n",
        "        data_root: Root folder containing the dataset\n",
        "        output_folder: Folder to save the prepared dataset\n",
        "        labels: List of class labels\n",
        "        annotations: Dictionary mapping image paths to lists of bounding boxes (optional)\n",
        "        split_ratio: Train/test split ratio\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the dataset configuration YAML file\n",
        "    \"\"\"\n",
        "    # Create train and val directories\n",
        "    train_images_dir = os.path.join(output_folder, 'images', 'train')\n",
        "    val_images_dir = os.path.join(output_folder, 'images', 'val')\n",
        "    train_labels_dir = os.path.join(output_folder, 'labels', 'train')\n",
        "    val_labels_dir = os.path.join(output_folder, 'labels', 'val')\n",
        "\n",
        "    for directory in [train_images_dir, val_images_dir, train_labels_dir, val_labels_dir]:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    all_images = []\n",
        "\n",
        "    # Process each class folder\n",
        "    for idx, label in enumerate(tqdm(labels, desc=\"Processing class folders\")):\n",
        "        if os.path.isdir(os.path.join(data_root, label)):\n",
        "            # Get all jpg images in the class folder\n",
        "            class_images = glob.glob(os.path.join(data_root, label, \"*.jpg\"))\n",
        "            for img_path in class_images:\n",
        "                all_images.append((img_path, idx))\n",
        "\n",
        "    # Split into train and val sets\n",
        "    random.shuffle(all_images)\n",
        "    split_idx = int(len(all_images) * split_ratio)\n",
        "    train_images = all_images[:split_idx]\n",
        "    val_images = all_images[split_idx:]\n",
        "\n",
        "    # Process train images\n",
        "    for img_path, label_id in tqdm(train_images, desc=\"Processing train images\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "        dest_path = os.path.join(train_images_dir, filename)\n",
        "        shutil.copy(img_path, dest_path)\n",
        "\n",
        "        # Create annotation if available\n",
        "        if annotations and img_path in annotations:\n",
        "            create_yolo_annotations(dest_path, label_id, annotations[img_path])\n",
        "        else:\n",
        "            # No annotations - use whole image as bounding box\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width = img.shape[:2]\n",
        "            create_yolo_annotations(dest_path, label_id, [[0, 0, width, height]])\n",
        "\n",
        "    # Process val images\n",
        "    for img_path, label_id in tqdm(val_images, desc=\"Processing val images\"):\n",
        "        filename = os.path.basename(img_path)\n",
        "        dest_path = os.path.join(val_images_dir, filename)\n",
        "        shutil.copy(img_path, dest_path)\n",
        "\n",
        "        # Create annotation if available\n",
        "        if annotations and img_path in annotations:\n",
        "            create_yolo_annotations(dest_path, label_id, annotations[img_path])\n",
        "        else:\n",
        "            # No annotations - use whole image as bounding box\n",
        "            img = cv2.imread(img_path)\n",
        "            height, width = img.shape[:2]\n",
        "            create_yolo_annotations(dest_path, label_id, [[0, 0, width, height]])\n",
        "\n",
        "    # Create dataset.yaml for YOLO\n",
        "    dataset_config = {\n",
        "        'path': output_folder,\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'nc': len(labels),\n",
        "        'names': labels\n",
        "    }\n",
        "\n",
        "    yaml_path = os.path.join(output_folder, 'dataset.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(dataset_config, f)\n",
        "\n",
        "    print(f\"Dataset prepared in YOLO format at {output_folder}\")\n",
        "    print(f\"Train images: {len(train_images)}\")\n",
        "    print(f\"Val images: {len(val_images)}\")\n",
        "    return yaml_path"
      ],
      "metadata": {
        "id": "fNrdpl5wYLF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_chest_ct_dataset(data_root, output_folder):\n",
        "    \"\"\"\n",
        "    Prepare chest CT dataset specifically for the lung cancer project\n",
        "\n",
        "    Args:\n",
        "        data_root: Path to the chest CT dataset\n",
        "        output_folder: Folder to save the prepared dataset\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the dataset configuration YAML file\n",
        "    \"\"\"\n",
        "    labels = ['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']\n",
        "\n",
        "    # For this dataset, we'll assume the structure from the original notebook\n",
        "    train_folder_names = [\n",
        "        'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib',\n",
        "        'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa',\n",
        "        'normal',\n",
        "        'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'\n",
        "    ]\n",
        "\n",
        "    # Create temporary folder to store processed images by class\n",
        "    temp_dir = os.path.join(output_folder, 'temp')\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    for folder_name, label in zip(train_folder_names, labels):\n",
        "        source_folder = os.path.join(data_root, 'train', folder_name)\n",
        "        target_folder = os.path.join(temp_dir, label)\n",
        "        os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "        if os.path.isdir(source_folder):\n",
        "            for img_file in tqdm(os.listdir(source_folder), desc=f\"Processing {folder_name}\"):\n",
        "                source_path = os.path.join(source_folder, img_file)\n",
        "                target_path = os.path.join(target_folder, img_file)\n",
        "\n",
        "                # Read, resize and save the image\n",
        "                img = cv2.imread(source_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (640, 640))  # YOLO default size\n",
        "                    cv2.imwrite(target_path, img)\n",
        "\n",
        "    # Also process the test data in the same way\n",
        "    for label in labels:\n",
        "        source_folder = os.path.join(data_root, 'test', label)\n",
        "        target_folder = os.path.join(temp_dir, label)\n",
        "\n",
        "        if os.path.isdir(source_folder):\n",
        "            for img_file in tqdm(os.listdir(source_folder), desc=f\"Processing test/{label}\"):\n",
        "                source_path = os.path.join(source_folder, img_file)\n",
        "                target_path = os.path.join(target_folder, f\"test_{img_file}\")\n",
        "\n",
        "                # Read, resize and save the image\n",
        "                img = cv2.imread(source_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (640, 640))  # YOLO default size\n",
        "                    cv2.imwrite(target_path, img)\n",
        "\n",
        "    # Prepare the dataset in YOLO format\n",
        "    yaml_path = prepare_dataset(temp_dir, output_folder, labels)\n",
        "\n",
        "    # Cleanup temporary directory\n",
        "    # shutil.rmtree(temp_dir)\n",
        "\n",
        "    return yaml_path\n"
      ],
      "metadata": {
        "id": "NJQJqroXYLDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_yolo12n():\n",
        "    \"\"\"\n",
        "    Download YOLO12n model weights if they don't exist\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the downloaded model\n",
        "    \"\"\"\n",
        "    model_path = \"yolo12n.pt\"\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"Downloading YOLO12n model...\")\n",
        "        # This is a placeholder - you'll need to replace with actual download link\n",
        "        # !wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt\n",
        "\n",
        "        # For now, we'll use YOLOv8n as a substitute\n",
        "        !wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt\n",
        "\n",
        "    return model_path"
      ],
      "metadata": {
        "id": "M3JcOyoiYLBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolo_model(data_yaml, pretrained_weights='yolo12n.pt', epochs=100, patience=15, img_size=640, batch_size=16):\n",
        "    \"\"\"\n",
        "    Train YOLO model on the prepared dataset\n",
        "\n",
        "    Args:\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "        pretrained_weights: Path to pretrained weights\n",
        "        epochs: Number of training epochs\n",
        "        patience: Early stopping patience\n",
        "        img_size: Image size for training\n",
        "        batch_size: Batch size\n",
        "\n",
        "    Returns:\n",
        "        YOLO: Trained YOLO model\n",
        "    \"\"\"\n",
        "    # Ensure the model weights are downloaded\n",
        "    model_weights = download_yolo12n()\n",
        "\n",
        "    print(f\"Loading {model_weights} model...\")\n",
        "    model = YOLO(model_weights)\n",
        "\n",
        "    print(f\"Training model for {epochs} epochs on {data_yaml}...\")\n",
        "    results = model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=epochs,\n",
        "        imgsz=img_size,\n",
        "        batch=batch_size,\n",
        "        patience=patience,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        verbose=True,\n",
        "        plots=True,\n",
        "        save=True\n",
        "    )\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "nqDIfmVZYK_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_yolo_model(model, data_yaml):\n",
        "    \"\"\"\n",
        "    Validate trained YOLO model\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "\n",
        "    Returns:\n",
        "        dict: Validation metrics\n",
        "    \"\"\"\n",
        "    print(\"Validating model...\")\n",
        "    results = model.val(data=data_yaml)\n",
        "\n",
        "    print(\"Validation results:\")\n",
        "    metrics = {\n",
        "        'precision': results.box.maps[0],  # mAP@0.5\n",
        "        'recall': results.box.mar[0],      # mAR@0.5\n",
        "        'mAP50': results.box.map50,        # mAP@0.5\n",
        "        'mAP50-95': results.box.map        # mAP@0.5:0.95\n",
        "    }\n",
        "\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"mAP@0.5: {metrics['mAP50']:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {metrics['mAP50-95']:.4f}\")\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "3vTThAWcYK8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, test_folder, num_samples=6, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Visualize model predictions on test images\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        test_folder: Folder containing test images\n",
        "        num_samples: Number of images to visualize\n",
        "        conf_threshold: Confidence threshold for predictions\n",
        "    \"\"\"\n",
        "    # Get test images\n",
        "    test_images = glob.glob(os.path.join(test_folder, '*.jpg'))[:num_samples]\n",
        "\n",
        "    # Create figure\n",
        "    n_cols = min(3, num_samples)\n",
        "    n_rows = (num_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
        "    axes = axes.flatten() if num_samples > 1 else [axes]\n",
        "\n",
        "    for i, img_path in enumerate(test_images):\n",
        "        if i >= num_samples:\n",
        "            break\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(img_path, conf=conf_threshold)[0]\n",
        "\n",
        "        # Get the original image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Plot results\n",
        "        axes[i].imshow(img)\n",
        "\n",
        "        # Draw bounding boxes and labels\n",
        "        for box in results.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            conf = float(box.conf[0])\n",
        "            cls_id = int(box.cls[0])\n",
        "            cls_name = results.names[cls_id]\n",
        "\n",
        "            # Draw rectangle\n",
        "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False,\n",
        "                                edgecolor='red', linewidth=2)\n",
        "            axes[i].add_patch(rect)\n",
        "\n",
        "            # Add label\n",
        "            axes[i].text(x1, y1-5, f\"{cls_name} {conf:.2f}\",\n",
        "                        color='white', fontsize=10,\n",
        "                        bbox=dict(facecolor='red', alpha=0.7))\n",
        "\n",
        "        axes[i].set_title(f\"Predictions for {os.path.basename(img_path)}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for i in range(len(test_images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EPGaQeHuYK0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_image(model, image_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Make prediction on a single image and visualize the results\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        image_path: Path to the image\n",
        "        conf_threshold: Confidence threshold for predictions\n",
        "\n",
        "    Returns:\n",
        "        results: YOLO prediction results\n",
        "    \"\"\"\n",
        "    # Run prediction\n",
        "    results = model.predict(image_path, conf=conf_threshold)[0]\n",
        "\n",
        "    # Get the original image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Visualize results\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for box in results.boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "        conf = float(box.conf[0])\n",
        "        cls_id = int(box.cls[0])\n",
        "        cls_name = results.names[cls_id]\n",
        "\n",
        "        # Draw rectangle\n",
        "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False,\n",
        "                            edgecolor='red', linewidth=2)\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        # Add label\n",
        "        plt.text(x1, y1-5, f\"{cls_name} {conf:.2f}\",\n",
        "                color='white', fontsize=10,\n",
        "                bbox=dict(facecolor='red', alpha=0.7))\n",
        "\n",
        "    plt.title(f\"Predictions for {os.path.basename(image_path)}\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "6V_XzK4CZSIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix(model, data_yaml):\n",
        "    \"\"\"\n",
        "    Create confusion matrix from model predictions\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "    \"\"\"\n",
        "    # Get validation results with confusion matrix\n",
        "    results = model.val(data=data_yaml, verbose=False)\n",
        "\n",
        "    # Extract confusion matrix\n",
        "    confusion_matrix = results.confusion_matrix.matrix\n",
        "\n",
        "    # Get class names\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    class_names = data_config['names']\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "setaFmBFZSGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_on_samples(model, data_yaml, num_samples=10):\n",
        "    \"\"\"\n",
        "    Test the model on sample images from each class (cancer and non-cancer)\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "        num_samples: Total number of samples to test (approximately equal from each class)\n",
        "    \"\"\"\n",
        "    print(f\"Testing model on {num_samples} sample images...\")\n",
        "\n",
        "    # Load dataset configuration\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = data_config['names']\n",
        "\n",
        "    # Path to validation images\n",
        "    val_images_dir = os.path.join(data_config['path'], data_config['val'])\n",
        "\n",
        "    # Get labels directory\n",
        "    val_labels_dir = os.path.join(data_config['path'], 'labels', 'val')\n",
        "\n",
        "    # Dict to store images by class\n",
        "    images_by_class = {cls: [] for cls in class_names}\n",
        "\n",
        "    # Find images with their ground truth classes\n",
        "    for label_file in glob.glob(os.path.join(val_labels_dir, '*.txt')):\n",
        "        # Get corresponding image path\n",
        "        image_name = os.path.basename(label_file).replace('.txt', '.jpg')\n",
        "        image_path = os.path.join(val_images_dir, image_name)\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "\n",
        "        # Read the first class from the label file (assuming one object per image)\n",
        "        with open(label_file, 'r') as f:\n",
        "            first_line = f.readline().strip()\n",
        "            if first_line:\n",
        "                try:\n",
        "                    class_id = int(first_line.split()[0])\n",
        "                    class_name = class_names[class_id]\n",
        "                    images_by_class[class_name].append(image_path)\n",
        "                except (IndexError, ValueError):\n",
        "                    continue\n",
        "\n",
        "    # If no proper labels found, just get random images\n",
        "    if all(len(imgs) == 0 for imgs in images_by_class.values()):\n",
        "        print(\"No labeled images found. Getting random samples...\")\n",
        "        all_images = glob.glob(os.path.join(val_images_dir, '*.jpg'))\n",
        "\n",
        "        # For demo, we'll classify 'normal' as non-cancer and others as cancer\n",
        "        cancer_classes = [cls for cls in class_names if cls != 'normal']\n",
        "\n",
        "        # Create two groups - estimate class from filename\n",
        "        for img_path in all_images:\n",
        "            filename = os.path.basename(img_path).lower()\n",
        "\n",
        "            if any(cls.lower() in filename for cls in cancer_classes):\n",
        "                # Randomly assign to a cancer class\n",
        "                random_cancer_class = random.choice([cls for cls in cancer_classes\n",
        "                                                    if cls.lower() in filename])\n",
        "                images_by_class[random_cancer_class].append(img_path)\n",
        "            elif 'normal' in filename:\n",
        "                images_by_class['normal'].append(img_path)\n",
        "\n",
        "    # Count total available images\n",
        "    total_available = sum(len(imgs) for imgs in images_by_class.values())\n",
        "    if total_available == 0:\n",
        "        print(\"No test images found. Please check your dataset.\")\n",
        "        return\n",
        "\n",
        "    # Select samples from each class (try to balance)\n",
        "    samples_per_class = max(1, num_samples // len(class_names))\n",
        "    selected_images = []\n",
        "\n",
        "    for cls, imgs in images_by_class.items():\n",
        "        # Select up to samples_per_class images from this class\n",
        "        cls_samples = random.sample(imgs, min(samples_per_class, len(imgs)))\n",
        "        selected_images.extend([(img, cls) for img in cls_samples])\n",
        "\n",
        "    # Shuffle the selected images\n",
        "    random.shuffle(selected_images)\n",
        "\n",
        "    # Limit to requested number of samples\n",
        "    selected_images = selected_images[:num_samples]\n",
        "\n",
        "    # Group into cancer and non-cancer for display\n",
        "    cancer_samples = []\n",
        "    non_cancer_samples = []\n",
        "\n",
        "    for img_path, cls in selected_images:\n",
        "        if cls == 'normal':\n",
        "            non_cancer_samples.append((img_path, cls))\n",
        "        else:\n",
        "            cancer_samples.append((img_path, cls))\n",
        "\n",
        "    # Testing on cancer samples\n",
        "    if cancer_samples:\n",
        "        print(f\"\\n---------- TESTING ON {len(cancer_samples)} CANCER SAMPLES ----------\")\n",
        "        for img_path, cls in cancer_samples:\n",
        "            print(f\"\\nGround truth: {cls} (CANCER)\")\n",
        "            results = predict_single_image(model, img_path)\n",
        "            # Print detection results\n",
        "            boxes = results.boxes\n",
        "            if len(boxes) == 0:\n",
        "                print(\"No detections found.\")\n",
        "            else:\n",
        "                for i, box in enumerate(boxes):\n",
        "                    conf = float(box.conf[0])\n",
        "                    cls_id = int(box.cls[0])\n",
        "                    cls_name = results.names[cls_id]\n",
        "                    cancer_status = \"CANCER\" if cls_name != \"normal\" else \"NON-CANCER\"\n",
        "                    print(f\"Detection {i+1}: {cls_name} ({cancer_status}) with confidence {conf:.2f}\")\n",
        "\n",
        "            # Small pause to let user see the results\n",
        "            time.sleep(1)\n",
        "\n",
        "    # Testing on non-cancer samples\n",
        "    if non_cancer_samples:\n",
        "        print(f\"\\n---------- TESTING ON {len(non_cancer_samples)} NON-CANCER SAMPLES ----------\")\n",
        "        for img_path, cls in non_cancer_samples:\n",
        "            print(f\"\\nGround truth: {cls} (NON-CANCER)\")\n",
        "            results = predict_single_image(model, img_path)\n",
        "            # Print detection results\n",
        "            boxes = results.boxes\n",
        "            if len(boxes) == 0:\n",
        "                print(\"No detections found.\")\n",
        "            else:\n",
        "                for i, box in enumerate(boxes):\n",
        "                    conf = float(box.conf[0])\n",
        "                    cls_id = int(box.cls[0])\n",
        "                    cls_name = results.names[cls_id]\n",
        "                    cancer_status = \"CANCER\" if cls_name != \"normal\" else \"NON-CANCER\"\n",
        "                    print(f\"Detection {i+1}: {cls_name} ({cancer_status}) with confidence {conf:.2f}\")\n",
        "\n",
        "            # Small pause to let user see the results\n",
        "            time.sleep(1)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n---------- TEST SUMMARY ----------\")\n",
        "    print(f\"Total samples tested: {len(selected_images)}\")\n",
        "    print(f\"Cancer samples: {len(cancer_samples)}\")\n",
        "    print(f\"Non-cancer samples: {len(non_cancer_samples)}\")\n",
        "    print(\"Test complete!\")"
      ],
      "metadata": {
        "id": "b6pRJm39ZSD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_demo_interface(model):\n",
        "    \"\"\"\n",
        "    Create a simple interface for making predictions on new images\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "    \"\"\"\n",
        "    from google.colab import files\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    # Function to handle file upload\n",
        "    def upload_and_predict():\n",
        "        clear_output()\n",
        "        print(\"Upload an image for prediction...\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"Predicting on {filename}...\")\n",
        "            file_path = filename\n",
        "            predict_single_image(model, file_path)\n",
        "\n",
        "    # Call the function\n",
        "    upload_and_predict()"
      ],
      "metadata": {
        "id": "53PjevW_ZSBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset():\n",
        "    \"\"\"\n",
        "    Process the chest CT dataset and prepare it for YOLO\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the dataset YAML file\n",
        "    \"\"\"\n",
        "    # Download dataset using kagglehub\n",
        "    print(\"Downloading chest CT scan dataset...\")\n",
        "    !pip install -q kagglehub\n",
        "    import kagglehub\n",
        "\n",
        "    # Download latest version of the dataset\n",
        "    data_path = kagglehub.dataset_download(\"mohamedhanyyy/chest-ctscan-images\")\n",
        "    print(f\"Dataset downloaded to: {data_path}\")\n",
        "\n",
        "    # Set output path\n",
        "    output_path = os.path.join(paths['data_dir'], 'processed_dataset')\n",
        "\n",
        "    # Prepare the dataset\n",
        "    yaml_path = prepare_chest_ct_dataset(data_path, output_path)\n",
        "\n",
        "    return yaml_path"
      ],
      "metadata": {
        "id": "FBfd9K0gZR-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(data_yaml, epochs=50):\n",
        "    \"\"\"\n",
        "    Train the YOLO12n model on the prepared dataset\n",
        "\n",
        "    Args:\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "        epochs: Number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        YOLO: Trained model\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    model = train_yolo_model(\n",
        "        data_yaml=data_yaml,\n",
        "        pretrained_weights='yolo12n.pt',\n",
        "        epochs=epochs,\n",
        "        patience=10,\n",
        "        img_size=640,\n",
        "        batch_size=16\n",
        "    )\n",
        "\n",
        "    # Validate the model\n",
        "    validate_yolo_model(model, data_yaml)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "B1yWWukyZR6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_yaml):\n",
        "    \"\"\"\n",
        "    Evaluate the model and visualize results\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "    \"\"\"\n",
        "    # Load dataset configuration\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    # Get path to test images\n",
        "    test_folder = os.path.join(data_config['path'], data_config['val'])\n",
        "\n",
        "    # Visualize predictions on test images\n",
        "    visualize_predictions(model, test_folder, num_samples=6)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    create_confusion_matrix(model, data_yaml)"
      ],
      "metadata": {
        "id": "_Io0PHJbZj7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_complete_workflow(epochs=50):\n",
        "    \"\"\"\n",
        "    Run the complete workflow from dataset preparation to model evaluation\n",
        "\n",
        "    Args:\n",
        "        epochs: Number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        YOLO: Trained model\n",
        "    \"\"\"\n",
        "    # 1. Process dataset\n",
        "    print(\"Step 1: Processing dataset...\")\n",
        "    data_yaml = process_dataset()\n",
        "\n",
        "    # 2. Train model\n",
        "    print(\"\\nStep 2: Training model...\")\n",
        "    model = train_model(data_yaml, epochs=epochs)\n",
        "\n",
        "    # 3. Evaluate model\n",
        "    print(\"\\nStep 3: Evaluating model...\")\n",
        "    evaluate_model(model, data_yaml)\n",
        "\n",
        "    # 4. Test on sample images\n",
        "    print(\"\\nStep 4: Testing on sample images...\")\n",
        "    test_model_on_samples(model, data_yaml, num_samples=10)\n",
        "\n",
        "    # 5. Demo interface\n",
        "    print(\"\\nStep 5: Creating demo interface...\")\n",
        "    create_demo_interface(model)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7YWzeS_NZj5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the complete workflow\n",
        "model = run_complete_workflow(epochs=50)\n"
      ],
      "metadata": {
        "id": "MFbb49Z3Zj2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the dataset\n",
        "data_yaml = process_dataset()"
      ],
      "metadata": {
        "id": "IK6hKxk8ZjzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = train_model(data_yaml, epochs=50)"
      ],
      "metadata": {
        "id": "KFVyHCTxZjva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluate_model(model, data_yaml)"
      ],
      "metadata": {
        "id": "XkwKlqXTZ1eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on sample images (5-10 images of cancer and non-cancer)\n",
        "test_model_on_samples(model, data_yaml, num_samples=10)"
      ],
      "metadata": {
        "id": "XLfCNHoLZ1b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create demo interface for uploading and testing new images\n",
        "create_demo_interface(model)"
      ],
      "metadata": {
        "id": "LGrS5vxzZ1ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_specific_images(model, image_paths, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Test the model on specific images\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        image_paths: List of paths to test images\n",
        "        conf_threshold: Confidence threshold for predictions\n",
        "    \"\"\"\n",
        "    for image_path in image_paths:\n",
        "        print(f\"\\nTesting on: {os.path.basename(image_path)}\")\n",
        "        results = predict_single_image(model, image_path, conf_threshold)\n",
        "\n",
        "        # Print detection results\n",
        "        boxes = results.boxes\n",
        "        if len(boxes) == 0:\n",
        "            print(\"No detections found.\")\n",
        "        else:\n",
        "            for i, box in enumerate(boxes):\n",
        "                conf = float(box.conf[0])\n",
        "                cls_id = int(box.cls[0])\n",
        "                cls_name = results.names[cls_id]\n",
        "                cancer_status = \"CANCER\" if cls_name != \"normal\" else \"NON-CANCER\"\n",
        "                print(f\"Detection {i+1}: {cls_name} ({cancer_status}) with confidence {conf:.2f}\")"
      ],
      "metadata": {
        "id": "U3M6WSICaEWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, filepath):\n",
        "    \"\"\"\n",
        "    Save the trained model\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        filepath: Path to save the model\n",
        "    \"\"\"\n",
        "    print(f\"Saving model to {filepath}...\")\n",
        "    model.export(format=\"onnx\")  # Save in ONNX format for wider compatibility\n",
        "\n",
        "    # Also save in PyTorch format\n",
        "    torch.save(model.model.state_dict(), filepath)\n",
        "    print(f\"Model saved to {filepath}\")\n",
        "\n",
        "def load_model(weights_path):\n",
        "    \"\"\"\n",
        "    Load a trained model\n",
        "\n",
        "    Args:\n",
        "        weights_path: Path to the saved model weights\n",
        "\n",
        "    Returns:\n",
        "        YOLO: Loaded model\n",
        "    \"\"\"\n",
        "    print(f\"Loading model from {weights_path}...\")\n",
        "    model = YOLO(weights_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "mpol23CFaETT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_performance_metrics(model, data_yaml):\n",
        "    \"\"\"\n",
        "    Calculate and visualize detailed performance metrics\n",
        "\n",
        "    Args:\n",
        "        model: Trained YOLO model\n",
        "        data_yaml: Path to the dataset YAML file\n",
        "\n",
        "    Returns:\n",
        "        dict: Detailed performance metrics\n",
        "    \"\"\"\n",
        "    print(\"Calculating performance metrics...\")\n",
        "\n",
        "    # Run validation\n",
        "    results = model.val(data=data_yaml)\n",
        "\n",
        "    # Extract metrics\n",
        "    metrics = {\n",
        "        'precision': results.box.maps[0],  # mAP@0.5\n",
        "        'recall': results.box.mar[0],      # mAR@0.5\n",
        "        'mAP50': results.box.map50,        # mAP@0.5\n",
        "        'mAP50-95': results.box.map,       # mAP@0.5:0.95\n",
        "        'f1': 2 * (results.box.maps[0] * results.box.mar[0]) /\n",
        "              (results.box.maps[0] + results.box.mar[0] + 1e-16)  # F1 score\n",
        "    }\n",
        "\n",
        "    # Load class names\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "    class_names = data_config['names']\n",
        "\n",
        "    # Get metrics per class\n",
        "    class_metrics = {}\n",
        "    for i, name in enumerate(class_names):\n",
        "        try:\n",
        "            precision = results.box.maps_per_class[i] if i < len(results.box.maps_per_class) else 0\n",
        "            recall = results.box.mar_per_class[i] if i < len(results.box.mar_per_class) else 0\n",
        "            class_metrics[name] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': 2 * (precision * recall) / (precision + recall + 1e-16)\n",
        "            }\n",
        "        except (IndexError, ZeroDivisionError):\n",
        "            class_metrics[name] = {'precision': 0, 'recall': 0, 'f1': 0}\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"\\nOverall Metrics:\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
        "    print(f\"mAP@0.5: {metrics['mAP50']:.4f}\")\n",
        "    print(f\"mAP@0.5:0.95: {metrics['mAP50-95']:.4f}\")\n",
        "\n",
        "    print(\"\\nMetrics per Class:\")\n",
        "    for cls, cls_metrics in class_metrics.items():\n",
        "        print(f\"{cls}:\")\n",
        "        print(f\"  Precision: {cls_metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {cls_metrics['recall']:.4f}\")\n",
        "        print(f\"  F1 Score: {cls_metrics['f1']:.4f}\")\n",
        "\n",
        "    # Plot metrics\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot per-class metrics\n",
        "    class_names_for_plot = list(class_metrics.keys())\n",
        "    precision_values = [class_metrics[cls]['precision'] for cls in class_names_for_plot]\n",
        "    recall_values = [class_metrics[cls]['recall'] for cls in class_names_for_plot]\n",
        "    f1_values = [class_metrics[cls]['f1'] for cls in class_names_for_plot]\n",
        "\n",
        "    x = np.arange(len(class_names_for_plot))\n",
        "    width = 0.25\n",
        "\n",
        "    plt.bar(x - width, precision_values, width, label='Precision')\n",
        "    plt.bar(x, recall_values, width, label='Recall')\n",
        "    plt.bar(x + width, f1_values, width, label='F1 Score')\n",
        "\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Performance Metrics by Class')\n",
        "    plt.xticks(x, class_names_for_plot, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {'overall': metrics, 'per_class': class_metrics}\n"
      ],
      "metadata": {
        "id": "CRCUUaO2aLIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and display detailed performance metrics\n",
        "metrics = calculate_performance_metrics(model, data_yaml)"
      ],
      "metadata": {
        "id": "gdNHNhYiaLGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}